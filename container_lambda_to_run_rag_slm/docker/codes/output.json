{"statusCode": 200, "body": "{\"query\": \"<|user|>\\nYou are an assistant for question-answering tasks. \\n    Use the context to answer the question. \\n    If you don't know the answer, just say that you don't know. \\n    Keep the answer concise.\\n\\n    Question: What is LoRA with respect to LLMs?<|end|>\\n<|assistant|>\", \"result\": \" LoRA (Low-Rank Adaptation) for Large Language Models (LLMs) aims to make finetuning more parameter-efficient by decomposing the weight changes into a lower-rank representation. This approach enables adaptation of pretrained LLMs to new tasks while maintaining most of their original parameters, allowing for improved performance on specialized domains with fewer computational resources.\"}"}